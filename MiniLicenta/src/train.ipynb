{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importuri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "from constants import PROCESSED_DATA_DIR, FILTERED_DATA_DIR, NUM_SAMPLES, SAMPLE_RATE, SNOMED_DICT, LEADS, NUM_LEADS, PLOT_DIR, CLASSIFIER_DATA_DIR, PLOT_DIR\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_classifier_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifier_data(selected_folders):\n",
    "    \"\"\"\n",
    "    X : np.ndarray de shape (N_samples, N_features)\n",
    "    Y : list of lists (multi-label)\n",
    "    \"\"\"\n",
    "    X_all = []\n",
    "    Y_all = []\n",
    "    record_names_all = []\n",
    "\n",
    "    for folder_name in selected_folders:\n",
    "        folder_path = CLASSIFIER_DATA_DIR / folder_name\n",
    "        if not folder_path.exists():\n",
    "            print(f\"[!!!] Folderul {folder_name} nu există în {CLASSIFIER_DATA_DIR}.skipp\")\n",
    "            continue\n",
    "\n",
    "        # Enumerăm fișierele .npy din folderul curent\n",
    "        batch_files = sorted([f for f in folder_path.iterdir() if f.is_file() and f.suffix == \".npy\"])\n",
    "        for bf in batch_files:\n",
    "            data_dict = np.load(bf, allow_pickle=True).item()\n",
    "            for record_name, rec_data in data_dict.items():\n",
    "                feats = rec_data[\"features\"]  \n",
    "                labels = rec_data[\"labels\"]   \n",
    "\n",
    "                X_all.append(feats)\n",
    "                Y_all.append(labels.tolist())  \n",
    "                record_names_all.append(record_name)\n",
    "\n",
    "    if len(X_all) == 0:\n",
    "        raise ValueError(\"no data folder\")\n",
    "\n",
    "    X_all = np.vstack(X_all) \n",
    "\n",
    "    return X_all, Y_all, record_names_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(X, Y):\n",
    "    \"\"\"\n",
    "    Mică funcție de verificare a datelor:\n",
    "      - shape\n",
    "      - valori lipsă (NaN)\n",
    "    \"\"\"\n",
    "    print(\"== Sanity check pe date ==\")\n",
    "    print(f\"X shape = {X.shape}\")\n",
    "    print(\"Număr de features per înregistrare:\", X.shape[1])\n",
    "    print(\"Features prezente (exemplu):\", [\n",
    "        'ventricular_rate', 'atrial_rate', 'qrs_duration',\n",
    "        'qt_interval', 'qrs_count', 'mean_r_onset_sec',\n",
    "        'mean_r_offset_sec', 'sex_binary', 'age'\n",
    "    ])\n",
    "    \n",
    "    # Verificăm NaN\n",
    "    nans_in_X = np.isnan(X).sum()\n",
    "    print(f\"Număr de NaN în X: {nans_in_X}\")\n",
    "\n",
    "    # coduri SNOMED\n",
    "    print(f\"Număr eșantioane (Y) = {len(Y)}\")\n",
    "    if len(X) != len(Y):\n",
    "        print(\"[WARNING] X și Y nu au aceeași lungime!\")\n",
    "    print(\"Exemplu Y[0]:\", Y[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Sanity check pe date ==\n",
      "X shape = (15000, 9)\n",
      "Număr de features per înregistrare: 9\n",
      "Features prezente (exemplu): ['ventricular_rate', 'atrial_rate', 'qrs_duration', 'qt_interval', 'qrs_count', 'mean_r_onset_sec', 'mean_r_offset_sec', 'sex_binary', 'age']\n",
      "Număr de NaN în X: 26\n",
      "Număr eșantioane (Y) = 15000\n",
      "Exemplu Y[0]: [164889003, 59118001, 164934002]\n",
      "Y_bin shape = (15000, 89)\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(31971) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(31973) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(32105) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(32111) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(32193) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(32194) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(32261) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(32412) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(32413) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(32423) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(32910) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cel mai bun scor (cv) obținut: 0.43168562186440473\n",
      "Parametrii cei mai buni: {'estimator__bootstrap': False, 'estimator__criterion': 'entropy', 'estimator__max_features': None, 'estimator__n_estimators': 800}\n",
      "[TRAIN] F1 final (pe același set) = 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/teofil/Dev/GitHub/ekg-classification-pipeline/plots/best_model.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Alegem folderele din care să antrenăm modelul\n",
    "selected_folders_train = [f\"{i:02d}\" for i in range(1, 16)]\n",
    "X, Y_list, record_names = load_classifier_data(selected_folders_train)\n",
    "sanity_check(X, Y_list)\n",
    "\n",
    "all_labels = set()\n",
    "for lab_list in Y_list:\n",
    "    all_labels.update(lab_list)\n",
    "all_labels = sorted(list(all_labels))\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=all_labels)\n",
    "Y_bin = mlb.fit_transform(Y_list)\n",
    "print(f\"Y_bin shape = {Y_bin.shape}\")\n",
    "\n",
    "clf = ExtraTreesClassifier(random_state=42)\n",
    "multi_clf = MultiOutputClassifier(clf)\n",
    "\n",
    "final_param_grid = {\n",
    "    \"estimator__n_estimators\": [300, 500, 800],\n",
    "    \"estimator__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"estimator__bootstrap\": [True, False],\n",
    "    \"estimator__max_features\": [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "scorer = make_scorer(f1_score, average=\"micro\")\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    multi_clf,\n",
    "    param_grid=final_param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=KFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    refit=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "    gs.fit(X, Y_bin)\n",
    "\n",
    "fail_indices = np.where(np.isnan(gs.cv_results_[\"mean_test_score\"]))[0]\n",
    "if len(fail_indices) > 0:\n",
    "    print(\"Seturi de parametri care au generat erori sau warning:\")\n",
    "    for idx in fail_indices:\n",
    "        print(\"Index:\", idx, \"Parametri:\", gs.cv_results_[\"params\"][idx])\n",
    "\n",
    "print(f\"Cel mai bun scor (cv) obținut: {gs.best_score_}\")\n",
    "print(f\"Parametrii cei mai buni: {gs.best_params_}\")\n",
    "\n",
    "best_model = gs.best_estimator_\n",
    "Y_pred = best_model.predict(X)\n",
    "final_f1 = f1_score(Y_bin, Y_pred, average=\"micro\")\n",
    "print(f\"[TRAIN] F1 final (pe același set) = {final_f1:.4f}\")\n",
    "\n",
    "joblib.dump(best_model, PLOT_DIR / \"best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
